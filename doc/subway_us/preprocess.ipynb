{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea58ffb-f2ef-4801-b8a3-16db1e820055",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4249065d-1b31-4cae-bec5-89b8fe99dd72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../../src/.\")\n",
    "from preprocess_data import data_transform_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5661713e-4ec0-4eeb-ad12-d79329d4ac05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = \"../../data/\"\n",
    "SUBWAYUS = \"Subway USA/subway_usa_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57338a90-e50f-4fe8-9148-7c25462115a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demographic = pd.read_csv(DIR + SUBWAYUS + \"demographic_variables.csv\")\n",
    "stores = pd.read_csv(DIR + SUBWAYUS + \"stores.csv\")\n",
    "poi_variables = pd.read_csv(DIR + SUBWAYUS + \"poi_variables.csv\")\n",
    "sister = pd.read_csv(DIR + SUBWAYUS + \"competition_sister_variables.csv\")\n",
    "trade_area = pd.read_csv(DIR + SUBWAYUS + \"trade_area_variables.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9e7a43-4882-4e29-8960-3a7ad170be31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged = stores.merge(\n",
    "    poi_variables, on=\"store\"\n",
    ").merge(\n",
    "    trade_area, on=\"store\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a5c1f3c-e7ab-460f-afd5-31f2aea66994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from preprocess_data import is_climate_feat\n",
    "\n",
    "def drop_specific_columns(df):\n",
    "    all_cols = df.columns.tolist()\n",
    "    keep_columns = []\n",
    "    \n",
    "    # drop features with corresponding percentage measures\n",
    "    percent_feats = [col for col in all_cols if \"_p_\" in col]\n",
    "    remove_feats = [\"_\".join(feat.split(\"_p_\")) for feat in percent_feats]\n",
    "\n",
    "    for col in all_cols:\n",
    "        if col in remove_feats:\n",
    "            continue\n",
    "        if \"centerxy\" in col:\n",
    "            if \"full\" not in col and \"effective\" not in col:\n",
    "                continue\n",
    "        if is_climate_feat(col):\n",
    "            continue\n",
    "        # remove sports venues columns (seems to be all zeros)\n",
    "        if \"sports_venues\" in col:\n",
    "            continue\n",
    "        if col.startswith('edu') and not col.startswith('edu_bachplus_p'):\n",
    "            continue\n",
    "        keep_columns.append(col)\n",
    "    print(f'----- Removing {len(all_cols) - len(keep_columns)} columns -----')\n",
    "    reduced_df = df[keep_columns]\n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e45764f-a2de-4bd2-8e93-5bac281a98b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Removing 95 columns -----\n"
     ]
    }
   ],
   "source": [
    "merged = drop_specific_columns(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4828827-4524-4a14-a229-08a78fea54a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(merged, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c2252b5-bd10-4f01-9f30-5410e9352caa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def agg_veh(df, columns=[]):\n",
    "    if len(columns) == 0:\n",
    "        columns = [\n",
    "            'hh_0vehicle_p_ta', 'hh_1vehicle_p_ta', 'hh_2vehicle_p_ta',\n",
    "            'hh_3vehicle_p_ta', 'hh_4vehicle_p_ta', 'hh_5vehicle_p_ta', \n",
    "        ]\n",
    "    df['hh_expected_vehicle_ta'] = df['hh_1vehicle_p_ta'] * 1 \n",
    "    + df['hh_2vehicle_p_ta'] * 2 \n",
    "    + df['hh_3vehicle_p_ta'] * 3 \n",
    "    + df['hh_4vehicle_p_ta'] * 4 \n",
    "    + df['hh_5vehicle_p_ta'] * 5\n",
    "    df.drop(columns=columns, inplace=True)\n",
    "\n",
    "agg_veh(train_df)\n",
    "agg_veh(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19586cf9-4b6e-4e64-adc4-95d5ea713229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def agg_hh_pers(df, columns=[]):\n",
    "    if len(columns) == 0:\n",
    "        columns = [\n",
    "            'hh_1pers_p_ta', 'hh_2pers_p_ta', 'hh_3pers_p_ta',\n",
    "            'hh_4pers_p_ta', 'hh_5pers_p_ta', 'hh_6pers_p_ta', \n",
    "            'hh_7pers_p_ta'\n",
    "        ]\n",
    "    df['hh_expected_pers_ta'] = df['hh_1pers_p_ta'] * 1 \n",
    "    + df['hh_2pers_p_ta'] * 2 \n",
    "    + df['hh_3pers_p_ta'] * 3 \n",
    "    + df['hh_4pers_p_ta'] * 4 \n",
    "    + df['hh_5pers_p_ta'] * 5\n",
    "    + df['hh_6pers_p_ta'] * 6\n",
    "    + df['hh_7pers_p_ta'] * 7\n",
    "    df.drop(columns=columns, inplace=True)\n",
    "\n",
    "agg_hh_pers(train_df)\n",
    "agg_hh_pers(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa2bf71-caa8-4631-8035-87258b1216f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_index = train_df['store']\n",
    "test_index = test_df['store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e350dd-3e1c-4e14-8407-8189f1d7de79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_features = [\n",
    "    \"store\", \n",
    "    \"longitude\", \n",
    "    \"latitude\", \n",
    "    # \"__store_latitude\",\n",
    "    # \"__store_longitude\",\n",
    "    # \"__batch_group\",\n",
    "    # \"__errors\",\n",
    "    # \"__store_bg\",\n",
    "    # \"__success\",\n",
    "]\n",
    "\n",
    "ordinal_features_oth = [\n",
    "    \"market_size\",\n",
    "    \"store_density\",\n",
    "]\n",
    "ordering_ordinal_oth = [\n",
    "    [\"Very Large Metro (1)\", \"Large Metro (2)\", \"Large City (3)\", \"Medium City (4)\", \"Small City (5)\", \"Small Town (6)\", \"Small Community (7)\"],\n",
    "    [\"Rural\", \"Exurban\", \"Suburban\", \"Light Suburban\", \"Light Urban\", \"Urban\", \"Super Urban\"],\n",
    "]\n",
    "categorical_features = [\"cbsa_name\", \"dma_name\", \"censusdivision\", \"censusregion\"]\n",
    "\n",
    "numeric_features = list(set(train_df.select_dtypes(include=np.number).columns.tolist()) - set(drop_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c78c0bc-b859-422f-93ea-506317aa3829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_train, processed_test = data_transform_pipeline(\n",
    "    train_df, \n",
    "    test_df, \n",
    "    train_index,\n",
    "    test_index,\n",
    "    drop_features + categorical_features, \n",
    "    ordinal_features_oth, \n",
    "    ordering_ordinal_oth, \n",
    "    [], \n",
    "    numeric_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74b294be-2c0a-4b4c-98de-eed417d91884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12944, 198)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "200b45d2-f589-4162-94cd-bf45013f563b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_train.to_csv(DIR + SUBWAYUS + \"processed_train.csv\")\n",
    "processed_test.to_csv(DIR + SUBWAYUS + \"processed_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f60e96-bc46-416d-b976-8ec74820b211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
